data:
  root: data/emg_data
  index: results/index.parquet
  features_root: results/features
  train_splits: [silent_parallel_data]
  val_splits: [silent_parallel_data]
  train_subsets: [train]   # hashed silent splits; switch to eval_silent if using the older index
  val_subsets: [val]
  vocab: configs/vocab.json
  include_teacher: false
  teacher_strict: false

features:
  emg:
    sample_rate: 1000
    n_fft: 320
    hop_length: 10
    n_mels: 80
    normalize: per_file
  teacher:
    model_name: microsoft/wavlm-base-plus
    layer: 9
    sample_rate: 16000
    dim: 768

model:
  encoder:
    d_model: 288
    num_layers: 6
    num_heads: 6
    ffn_dim: 1152
    depthwise_conv_kernel_size: 15
    dropout: 0.1
    subsample_factor: 2   # keep CTC resolution for silent EMG
    input_dim: 640
  projection_dim: 768
  ctc_dropout: 0.1

loss:
  lambda_distill: 0.0
  lambda_ctc: 1.0
  distill_warmup_epochs: 0

optim:
  batch_size: 2          # stabilize updates; use grad_accum for effective batch 4
  grad_accum: 2
  lr: 1.5e-4
  weight_decay: 5e-3
  max_epochs: 50
  clip_grad_norm: 5.0
  num_workers: 4
  prefetch_factor: 2
  pin_memory: true
  scheduler:
    name: cosine
    t_max: 50000
    eta_min: 5e-5
  early_stopping:
    patience: 8
    min_delta: 0.0

augmentation:
  specaugment:
    time_masks: 1
    time_mask_width: 0.05
    freq_masks: 1
    freq_mask_width: 6
    p: 0.08
  channel_dropout:
    p: 0.0

decoding:
  type: beam
  beam_width: 60
  alpha: 0.4
  beta: 0.0
  beam_prune_logp: -10.0
  lm_path: null

logging:
  seed: 42
  run_name: mps_silent_finetune_plus
  log_interval: 10
