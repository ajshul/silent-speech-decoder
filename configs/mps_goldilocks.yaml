data:
  root: data/emg_data
  index: results/index.parquet
  features_root: results/features
  train_splits: [voiced_parallel_data]
  val_splits: [voiced_parallel_data]
  train_subsets: [train]
  val_subsets: [val]
  vocab: configs/vocab.json

features:
  emg:
    sample_rate: 1000
    n_fft: 320
    hop_length: 10
    n_mels: 80
    normalize: per_file
  teacher:
    model_name: microsoft/wavlm-base-plus
    layer: 9
    sample_rate: 16000
    dim: 768

model:
  encoder:
    d_model: 288        # wider hidden size
    num_layers: 8       # slightly deeper
    num_heads: 8        # keeps d_model divisible by heads
    ffn_dim: 1152       # ~4x d_model for balance
    depthwise_conv_kernel_size: 15
    dropout: 0.1
    subsample_factor: 2
  projection_dim: 768
  ctc_dropout: 0.1

loss:
  lambda_distill: 0.25
  lambda_ctc: 0.75
  distill_warmup_epochs: 3

optim:
  batch_size: 3      # modestly reduced for the larger model on MPS
  grad_accum: 2
  lr: 3e-4
  weight_decay: 1e-2
  max_epochs: 40
  clip_grad_norm: 5.0
  num_workers: 2
  prefetch_factor: 1
  pin_memory: true
  scheduler:
    name: linear
    warmup_steps: 500
  early_stopping:
    patience: 4
    min_delta: 0.0

augmentation:
  specaugment:
    time_masks: 2
    time_mask_width: 0.05
    freq_masks: 2
    freq_mask_width: 8
    p: 0.5

logging:
  seed: 42
  run_name: mps_goldilocks
  log_interval: 10
